# Spatial-Temporal Transformer for Dynamic Scene Graph Generation
Pytorch Implementation of our paper [Spatial-Temporal Transformer for Dynamic Scene Graph Generation](https://arxiv.org/abs/2107.12309) accepted by **ICCV2021**. We propose a Transformer-based model **STTran** to generate dynamic scene graphs of the given video. **STTran** can detect the visual relationships in each frame.

![GitHub Logo](/data/framework.png)

**About the code**
We run the code on a single RTX2080ti for both training and testing. We borrowed some code from [Yang's repository](https://github.com/jwyang/faster-rcnn.pytorch) and [Zellers' repository](https://github.com/rowanz/neural-motifs).


## Dataset

## Citation
If our work is helpful for your research, please cite our publication:
```
@article{cong2021spatial,
  title={Spatial-Temporal Transformer for Dynamic Scene Graph Generation},
  author={Cong, Yuren and Liao, Wentong and Ackermann, Hanno and Yang, Michael Ying and Rosenhahn, Bodo},
  journal={arXiv preprint arXiv:2107.12309},
  year={2021}
}
```
